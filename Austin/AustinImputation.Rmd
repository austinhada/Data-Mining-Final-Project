---
title: "Imputation"
author: "L. Austin Hadamuscin"
date: "4/7/2022"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(FNN)
library(DMwR)
library(caret)
```

# Data
```{r}
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
```


# Which columns have missing data?
```{r}
na_columns <- colSums(is.na(dat))

na_columns[na_columns >0]
```


# complete data
```{r}
complete_dat <- dat_numeric[complete.cases(dat_numeric),]
incomplete_dat <- dat_numeric[!complete.cases(dat_numeric),]
```

# Scale the Data
```{r}
scaled_complete <- scale(complete_dat)
complete_Attributes <- attributes(scaled_complete)

scaled_incomplete <- scale(incomplete_dat,
                            center = complete_Attributes$`scaled:center`,
                            scale = complete_Attributes$`scaled:scale`)

scaled_together <- dat_numeric
scaled_together[complete.cases(dat_numeric),] <- scaled_complete
scaled_together[!complete.cases(dat_numeric),] <- scaled_incomplete

```

# Finding the optimal k for each imputation
```{r}
train_control <- trainControl(method = "LOOCV")

train(HALE_Birth ~ .,
      data = scaled_complete,
      method = "knn",
      trControl = train_control,
      preProcess = c("center","scale"),
      tuneGrid = data.frame(k=1:12)) |> plot()

optimal_k <- 3
```


# knn imputation function
```{r}
# Number of rows
n <- nrow(dat_numeric)

# Number of columns
numcol <- ncol(dat_numeric)

# Data to a matrix
data.mat <- as.matrix(scaled_together)

# indices of rows with NA
tgt.nas <- which(!complete.cases(dat_numeric))

# For every row containing NA
for (i in tgt.nas) {
  
  # From the scale() documentation:
  # If center is a numeric-alike vector with length equal to the number of
  # columns of x, then each column of x has the corresponding value from center
  # subtracted from it.
  dist <- scale(x = complete_dat,
                center = data.mat[i, ], # row with NA
                scale = FALSE)
  
  # Which column is the NA in?
  tgtAs <- which(is.na(data.mat[i, ]))
  
  # Remove the distances who's columns contain NA
  dist <- dist[, -tgtAs]
  
  # Calculates the Euclidean distance
  dist <- sqrt(drop(dist^2 %*% rep(1, ncol(dist))))
  
  # Gets the indices of the optimal number of nearest neighbors specified by optimal_k
  ks <- order(dist)[seq(optimal_k)]
  
  # Imputing the mean of the optimal number nearest neighbors
  for (j in tgtAs) imputed_dat[i, j+1] <- mean(dat_numeric[-tgt.nas, j][ks])
  
}
```


# Save the Data
```{r}
#write.csv(imputed_dat, file = "C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/imputedData.csv", row.names = F)
```