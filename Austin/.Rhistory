View(complete_dat)
View(incomplete_dat)
View(complete_dat)
View(incomplete_dat)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(FNN)
library(dplyr)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
apply(dat_numeric, 2, function(i)sum(is.na(i)))
summary(dat)
na_columns <- colSums(is.na(dat))
na_columns[na_columns >0]
View(dat_numeric)
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
View(HepB_incomplete)
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[!naRow_HepB,                       # Row
c("HepB",names(HepB_incomplete))]  # Col
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[!naRow_HepB,]  # Col
View(HepB_complete)
names(HepB_incomplete)
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[!naRow_HepB,                       # Row
c("HepB",names(HepB_incomplete))]  # Col
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[complete.cases(dat_numeric),       # Row
c("HepB",names(HepB_incomplete))]  # Col
View(HepB_complete)
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[complete.cases(dat_numeric),       # Row
c("HepB",names(HepB_incomplete))]  # Col
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
View(HepB_incomplete)
View(dat)
hist(dat$Measles)
hist(dat$Measles, breaks = 100)
=median(dat$Measles)
median(dat$Measles)
median(dat$Measles, na.rm = T)
mean(dat$Measles, na.rm = T)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(FNN)
library(dplyr)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
apply(dat_numeric, 2, function(i)sum(is.na(i)))
summary(dat)
na_columns <- colSums(is.na(dat))
na_columns[na_columns >0]
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[complete.cases(dat_numeric),       # Row
c("HepB",names(HepB_incomplete))]  # Col
scaled_HepB_comp <- scale(HepB_complete[,-1])
HepB_Attributes <- attributes(scaled_HepB_comp)
scaled_HepB_incomp <- scale(HepB_incomplete,
center = HepB_Attributes$`scaled:center`,
scale = HepB_Attributes$`scaled:scale`)
# Setting up LOOCV
train_control <- trainControl(method = "LOOCV")
# Data mining k
loocv_HepB <- train(HALE_Birth ~ .,
data = scaled_HepB_comp,
method = "knn",
trControl = train_control,
preProcess = c("center","scale"),
tuneGrid = data.frame(k=1:12))   #there are 12 regressors
plot(loocv_HepB)
# Getting the optimized k nearest neighbors
HepB_nn <- get.knnx(scaled_HepB_comp, scaled_HepB_incomp, k=2)
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(FNN)
library(dplyr)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
apply(dat_numeric, 2, function(i)sum(is.na(i)))
summary(dat)
na_columns <- colSums(is.na(dat))
na_columns[na_columns >0]
# Row numbers that have NA in the HepB column
naRow_HepB <- !complete.cases(dat_numeric[,"HepB"])
# Grab rows with NA in the HepB columns
HepB_incomplete <- dat_numeric[naRow_HepB,]
# Getting rid of Columns with NA
HepB_incomplete <- HepB_incomplete[,colSums(!is.na(HepB_incomplete))==nrow(HepB_incomplete)]
# Removing the NA HepB rows, and choosing the columns that are complete
# for the above dataset
HepB_complete <- dat_numeric[complete.cases(dat_numeric),       # Row
c("HepB",names(HepB_incomplete))]  # Col
scaled_HepB_comp <- scale(HepB_complete[,-1])
HepB_Attributes <- attributes(scaled_HepB_comp)
scaled_HepB_incomp <- scale(HepB_incomplete,
center = HepB_Attributes$`scaled:center`,
scale = HepB_Attributes$`scaled:scale`)
train_control <- trainControl(method = "LOOCV")
# Data mining k
loocv_HepB <- train(HALE_Birth ~ .,
data = scaled_HepB_comp,
method = "knn",
trControl = train_control,
preProcess = c("center","scale"),
tuneGrid = data.frame(k=1:12))   #there are 12 regressors
plot(loocv_HepB)
# Getting the optimized k nearest neighbors
HepB_nn <- get.knnx(scaled_HepB_comp, scaled_HepB_incomp, k=4)
HepB_nn
View(HepB_complete)
# Getting the optimized k nearest neighbors
HepB_nn <- get.knnx(data = scaled_HepB_comp,
query = scaled_HepB_incomp,
k=4)
# Getting the optimized k nearest neighbors
HepB_nn <- get.knnx(data = scaled_HepB_comp,
query = scaled_HepB_incomp,
k=4)
HepB_index <- HepB_nn$nn.index
HepB_index
HepB_complete$HepB[HepB_index]
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T)
HepB_index
HepB_complete$HepB[HepB_index]
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T)
HepB_index
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T)
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T) %>%
rowMeans()
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T) %>%
rowMeans()
imputed_dat$HepB[naRow_HepB]
# Setting up LOOCV
train_control <- trainControl(method = "LOOCV")
# Data mining k
loocv_HepB <- train(HALE_Birth ~ .,
data = scaled_HepB_comp,
method = "knn",
trControl = train_control,
preProcess = c("center","scale"),
tuneGrid = data.frame(k=1:12))   #there are 12 regressors
plot(loocv_HepB)
knn.reg()
# Getting the optimized k nearest neighbors
HepB_nn <- get.knnx(data = scaled_HepB_comp,
query = scaled_HepB_incomp,
k=4)
HepB_index <- HepB_nn$nn.index
HepB_complete$HepB[HepB_index] %>%
matrix(ncol = 4, byrow = T) %>%
rowMeans() -> imputed_dat$HepB[naRow_HepB]
imputed_dat$HepB[naRow_HepB]
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(FNN)
library(DMwR)
library(caret)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
na_columns <- colSums(is.na(dat))
na_columns[na_columns >0]
complete_dat <- dat_numeric[complete.cases(dat_numeric),]
incomplete_dat <- dat_numeric[!complete.cases(dat_numeric),]
scaled_complete <- scale(complete_dat)
complete_Attributes <- attributes(scaled_complete)
scaled_incomplete <- scale(incomplete_dat,
center = complete_Attributes$`scaled:center`,
scale = complete_Attributes$`scaled:scale`)
scaled_together <- dat_numeric
scaled_together[complete.cases(dat_numeric),] <- scaled_complete
scaled_together[!complete.cases(dat_numeric),] <- scaled_incomplete
# train_control <- trainControl(method = "LOOCV")
#
# train(HALE_Birth ~ .,
#       data = scaled_complete,
#       method = "knn",
#       trControl = train_control,
#       preProcess = c("center","scale"),
#       tuneGrid = data.frame(k=1:12)) |> plot()
optimal_k <- 5
# Number of rows
n <- nrow(dat_numeric)
# Number of columns
numcol <- ncol(dat_numeric)
# Data to a matrix
data.mat <- as.matrix(scaled_together)
# indices of rows with NA
tgt.nas <- which(!complete.cases(dat_numeric))
# For every row containing NA
for (i in tgt.nas) {
# From the scale() documentation:
# If center is a numeric-alike vector with length equal to the number of
# columns of x, then each column of x has the corresponding value from center
# subtracted from it.
dist <- scale(x = complete_dat,
center = data.mat[i, ], # row with NA
scale = FALSE)
# Which column is the NA in?
tgtAs <- which(is.na(data.mat[i, ]))
# Remove the distances who's columns contain NA
dist <- dist[, -tgtAs]
# Calculates the Euclidean distance
dist <- sqrt(drop(dist^2 %*% rep(1, ncol(dist))))
# Gets the indices of the optimal number of nearest neighbors specified by optimal_k
ks <- order(dist)[seq(optimal_k)]
# Imputing the mean of the optimal number nearest neighbors
for (j in tgtAs) imputed_dat[i, j+1] <- mean(data.mat[-tgt.nas, j][ks])
}
View(imputed_dat)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(FNN)
library(DMwR)
library(caret)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/life14updated.csv")
dat_numeric <- select(dat, -Country)
imputed_dat <- dat
na_columns <- colSums(is.na(dat))
na_columns[na_columns >0]
complete_dat <- dat_numeric[complete.cases(dat_numeric),]
incomplete_dat <- dat_numeric[!complete.cases(dat_numeric),]
scaled_complete <- scale(complete_dat)
complete_Attributes <- attributes(scaled_complete)
scaled_incomplete <- scale(incomplete_dat,
center = complete_Attributes$`scaled:center`,
scale = complete_Attributes$`scaled:scale`)
scaled_together <- dat_numeric
scaled_together[complete.cases(dat_numeric),] <- scaled_complete
scaled_together[!complete.cases(dat_numeric),] <- scaled_incomplete
# train_control <- trainControl(method = "LOOCV")
#
# train(HALE_Birth ~ .,
#       data = scaled_complete,
#       method = "knn",
#       trControl = train_control,
#       preProcess = c("center","scale"),
#       tuneGrid = data.frame(k=1:12)) |> plot()
optimal_k <- 5
# Number of rows
n <- nrow(dat_numeric)
# Number of columns
numcol <- ncol(dat_numeric)
# Data to a matrix
data.mat <- as.matrix(scaled_together)
# indices of rows with NA
tgt.nas <- which(!complete.cases(dat_numeric))
# For every row containing NA
for (i in tgt.nas) {
# From the scale() documentation:
# If center is a numeric-alike vector with length equal to the number of
# columns of x, then each column of x has the corresponding value from center
# subtracted from it.
dist <- scale(x = complete_dat,
center = data.mat[i, ], # row with NA
scale = FALSE)
# Which column is the NA in?
tgtAs <- which(is.na(data.mat[i, ]))
# Remove the distances who's columns contain NA
dist <- dist[, -tgtAs]
# Calculates the Euclidean distance
dist <- sqrt(drop(dist^2 %*% rep(1, ncol(dist))))
# Gets the indices of the optimal number of nearest neighbors specified by optimal_k
ks <- order(dist)[seq(optimal_k)]
# Imputing the mean of the optimal number nearest neighbors
for (j in tgtAs) imputed_dat[i, j+1] <- mean(dat_numeric[-tgt.nas, j][ks])
}
write.csv(imputed_dat, file = "C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/imputedData.csv", row.names = F)
View(imputed_dat)
# Number of rows
n <- nrow(dat_numeric)
# Number of columns
numcol <- ncol(dat_numeric)
# Data to a matrix
data.mat <- as.matrix(scaled_together)
# indices of rows with NA
tgt.nas <- which(!complete.cases(dat_numeric))
# For every row containing NA
for (i in tgt.nas) {
# From the scale() documentation:
# If center is a numeric-alike vector with length equal to the number of
# columns of x, then each column of x has the corresponding value from center
# subtracted from it.
dist <- scale(x = complete_dat,
center = data.mat[i, ], # row with NA
scale = FALSE)
# Which column is the NA in?
tgtAs <- which(is.na(data.mat[i, ]))
# Remove the distances who's columns contain NA
dist <- dist[, -tgtAs]
# Calculates the Euclidean distance
dist <- sqrt(drop(dist^2 %*% rep(1, ncol(dist))))
# Gets the indices of the optimal number of nearest neighbors specified by optimal_k
ks <- order(dist)[seq(optimal_k)]
# Imputing the mean of the optimal number nearest neighbors
for (j in tgtAs) imputed_dat[i, j+1] <- mean(dat_numeric[-tgt.nas, j][ks])
}
summary(imputed_dat)
summary(dat)
summary(imputed_dat)
write.csv(imputed_dat, file = "C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/imputedData.csv", row.names = F)
knitr::opts_chunk$set(echo = TRUE)
library(sampling)
library(tidyverse)
library(rworldmap)
library(mclust)
dat <- read.csv("C:/Users/hadamul/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/imputedData.csv")
dat <- read.csv("C:/Users/drumm/OneDrive/Graduate school/Semester 4/Data Mining/Data-Mining-Final-Project/imputedData.csv")
dat_scaled <- scale(select(dat, -Country, -Measles, -HALE_Birth))
RNGkind (sample.kind = "Rounding")
set.seed(0)
nseeds <- 1000
nk <- 20
seeds <- ceiling(runif(nseeds,0,900000))
kmean_matrix  <- matrix(NA, nrow = nseeds, ncol = nk)
for (k in 1:nk) {
seed_iter = 0
for (s in seeds) {
set.seed(s)
seed_iter <- seed_iter + 1
kmean_matrix[seed_iter,k] <- kmeans(dat_scaled, centers = k)$tot.withinss
}
}
# save(kmean_matrix, file = "kmean_matrix.RData")
load("kmean_matrix.RData")
RNGkind (sample.kind = "Rounding")
set.seed(0)
nseeds <- 1000
nk <- 20
seeds <- ceiling(runif(nseeds,0,900000))
# kmean_matrix  <- matrix(NA, nrow = nseeds, ncol = nk)
#
# for (k in 1:nk) {
#   seed_iter = 0
#   for (s in seeds) {
#
#     set.seed(s)
#     seed_iter <- seed_iter + 1
#
#     kmean_matrix[seed_iter,k] <- kmeans(dat_scaled, centers = k)$tot.withinss
#   }
# }
# save(kmean_matrix, file = "kmean_matrix.RData")
load("kmean_matrix.RData")
plot(1:nk,apply(kmean_matrix, 2, min),
type = "l",
ylab = "wss",
xlab = "k")
kmean_seed2 <- seeds[which(kmean_matrix[,2]==min(kmean_matrix[,2]))[1]]
kmean_seed4 <- seeds[which(kmean_matrix[,4]==min(kmean_matrix[,4]))[1]]
kmean_seed5 <- seeds[which(kmean_matrix[,5]==min(kmean_matrix[,5]))[1]]
kmean_seed6 <- seeds[which(kmean_matrix[,6]==min(kmean_matrix[,6]))[1]]
set.seed(kmean_seed2)
means2 <- kmeans(dat_scaled, centers = 2)
set.seed(kmean_seed4)
means4 <- kmeans(dat_scaled, centers = 4)
set.seed(kmean_seed5)
means5 <- kmeans(dat_scaled, centers = 5)
set.seed(kmean_seed6)
means6 <- kmeans(dat_scaled, centers = 6)
means2$withinss
means6$withinss
clust2 <- cbind(select(dat, Country, HALE_Birth),cluster = means2$cluster,dat)
clust4 <- cbind(select(dat, Country, HALE_Birth),cluster = means4$cluster,dat)
clust5 <- cbind(select(dat, Country, HALE_Birth),cluster = means5$cluster,dat)
clust6 <- cbind(select(dat, Country, HALE_Birth),cluster = means6$cluster,dat)
clust5_map <- joinCountryData2Map(clust5, joinCode = "NAME",
nameJoinColumn = "Country")
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = clust5_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow",)
clust4_map <- joinCountryData2Map(clust4, joinCode = "NAME",
nameJoinColumn = "Country")
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = clust4_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow",)
clust2_map <- joinCountryData2Map(clust2, joinCode = "NAME",
nameJoinColumn = "Country")
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = clust2_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow",)
clust6_map <- joinCountryData2Map(clust6, joinCode = "NAME", nameJoinColumn = "Country")
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = clust6_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow")
mb_rep <- 20
mb_matrix <- matrix(NA, 14, mb_rep)
mb_dat <- select(dat, -Country,-Measles, -HALE_Birth)
for (k in 1:mb_rep) {
mb_matrix[,k] <- Mclust(mb_dat, k)$BIC
}
mb_rep <- 20
mb_matrix <- matrix(NA, 14, mb_rep)
mb_dat <- select(dat, -Country,-Measles, -HALE_Birth)
# for (k in 1:mb_rep) {
#   mb_matrix[,k] <- Mclust(mb_dat, k)$BIC
# }
# save(mb_matrix,file = "mb_matrix.RData")
load("mb_matrix.RData")
plot(x=1:20,
y=apply(mb_matrix, 2, function(i) min(i,na.rm = T)),
type = "b",
xlab = "k",
ylab = "BIC")
mb_rep <- 20
mb_matrix <- matrix(NA, 14, mb_rep)
mb_dat <- select(dat, -Country,-Measles, -HALE_Birth)
for (k in 1:mb_rep) {
mb_matrix[,k] <- Mclust(mb_dat, k)$BIC
}
save(mb_matrix,file = "mb_matrix.RData")
load("mb_matrix.RData")
plot(x=1:20,
y=apply(mb_matrix, 2, function(i) min(i,na.rm = T)),
type = "b",
xlab = "k",
ylab = "BIC")
mb3 <- Mclust(mb_dat, 3, verbose = F)
#
# save(mb3, file = "mb3.RData")
load("mb3.RData")
round(mb3$parameters$mean)
mb3 <- Mclust(mb_dat, 3, verbose = F)
mb4 <- Mclust(mb_dat, 4, verbose = F)
save(mb3, file = "mb3.RData")
save(mb4, file = "mb4.RData")
load("mb3.RData")
load("mb4.RData")
# round(mb3$parameters$mean)
mbclust3 <- cbind(select(dat, Country, HALE_Birth),cluster = mb3$classification,dat)
mbclust4 <- cbind(select(dat, Country, HALE_Birth),cluster = mb4$classification,dat)
mbclust4_map <- joinCountryData2Map(mbclust4, joinCode = "NAME", nameJoinColumn = "Country", )
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = mbclust4_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow")
mbclust3_map <- joinCountryData2Map(mbclust3, joinCode = "NAME", nameJoinColumn = "Country", )
par(mar=c(0,0,1,0))
mapCountryData(mapToPlot = mbclust3_map,
nameColumnToPlot="cluster",
catMethod="categorical",
colourPalette = "rainbow")
clust2
means2$centers
